<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HWZ</title>
  
  <subtitle>双木成林</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hhh0hwz.github.io/"/>
  <updated>2020-10-10T12:38:32.753Z</updated>
  <id>https://hhh0hwz.github.io/</id>
  
  <author>
    <name>HWZ</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>cold-start survey</title>
    <link href="https://hhh0hwz.github.io/2020/10/05/cold-start-survey/"/>
    <id>https://hhh0hwz.github.io/2020/10/05/cold-start-survey/</id>
    <published>2020-10-05T05:38:44.000Z</published>
    <updated>2020-10-10T12:38:32.753Z</updated>
    
    <content type="html"><![CDATA[<h5 id="keyword"><a href="#keyword" class="headerlink" title="keyword"></a>keyword</h5><p><em>cold-start，cross domain， sparse</em></p><h3 id="2020WWW"><a href="#2020WWW" class="headerlink" title="2020WWW"></a>2020WWW</h3><h5 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h5><ul><li>Deep Transfer Learning for Search and Recommendation </li></ul><h5 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h5><ul><li><p><strong>PKE: A Model for Recommender Systems in Online Service Platform</strong></p><p><a href="https://dl.acm.org/doi/10.1145/3366424.3382090" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3366424.3382090</a></p></li><li><p>Treating Cold Start in Product Search by Priors</p><p><a href="https://dl.acm.org/doi/10.1145/3366424.3382705" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3366424.3382705</a></p></li><li><p>Time Series Forecasting for Cold-Start Items by Learning from Related Items using Memory Networks</p><p><a href="https://dl.acm.org/doi/10.1145/3366424.3382728" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3366424.3382728</a></p></li></ul><h3 id="2020KDD"><a href="#2020KDD" class="headerlink" title="2020KDD"></a>2020KDD</h3><h5 id="paper-1"><a href="#paper-1" class="headerlink" title="paper"></a>paper</h5><ul><li><p>A Block Decomposition Algorithm for Sparse Optimization</p><p><a href="https://www.kdd.org/kdd2020/accepted-papers/view/a-block-decomposition-algorithm-for-sparse-optimization" target="_blank" rel="noopener">https://www.kdd.org/kdd2020/accepted-papers/view/a-block-decomposition-algorithm-for-sparse-optimization</a></p></li><li><p>MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation</p><p><a href="https://www.kdd.org/kdd2020/accepted-papers/view/mamo-memory-augmented-meta-optimization-for-cold-start-recommendation" target="_blank" rel="noopener">https://www.kdd.org/kdd2020/accepted-papers/view/mamo-memory-augmented-meta-optimization-for-cold-start-recommendation</a></p></li><li><p><strong>Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation</strong></p><p><a href="https://www.kdd.org/kdd2020/accepted-papers/view/meta-learning-on-heterogeneous-information-networks-for-cold-start-recommen" target="_blank" rel="noopener">https://www.kdd.org/kdd2020/accepted-papers/view/meta-learning-on-heterogeneous-information-networks-for-cold-start-recommen</a></p></li><li><p>A Dual Heterogeneous Graph Attention Network to Improve Long-Tail Performance for Shop Search in E-Commerce</p><p>长尾物体</p><p><a href="https://www.kdd.org/kdd2020/accepted-papers/view/a-dual-heterogeneous-graph-attention-network-to-improve-long-tail-performan" target="_blank" rel="noopener">https://www.kdd.org/kdd2020/accepted-papers/view/a-dual-heterogeneous-graph-attention-network-to-improve-long-tail-performan</a></p></li></ul><h3 id="2019WWW"><a href="#2019WWW" class="headerlink" title="2019WWW"></a>2019WWW</h3><h5 id="paper-2"><a href="#paper-2" class="headerlink" title="paper"></a>paper</h5><ul><li><p>Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation</p><p><a href="https://dl.acm.org/doi/10.1145/3308558.3313411" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3308558.3313411</a></p></li><li><p>Cross-domain Recommendation Without Sharing User-relevant Data</p><p><a href="https://dl.acm.org/doi/10.1145/3308558.3313538" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3308558.3313538</a></p></li><li><p>Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain Collaborative Filtering with Text</p><p><a href="https://dl.acm.org/doi/abs/10.1145/3308558.3313543" target="_blank" rel="noopener">https://dl.acm.org/doi/abs/10.1145/3308558.3313543</a></p></li></ul><h3 id="2018-WWW"><a href="#2018-WWW" class="headerlink" title="2018 WWW"></a>2018 WWW</h3><h5 id="paper-3"><a href="#paper-3" class="headerlink" title="paper"></a>paper</h5><ul><li><p>Aspect-Aware Latent Factor Model:Rating Prediction with Ratings and Reviews</p><p><a href="https://arxiv.org/pdf/1802.07938.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1802.07938.pdf</a></p></li><li><p>Cold Start Thread Recommendation as Extreme Multi-label Classification</p><p><a href="https://dl.acm.org/doi/10.1145/3184558.3191659" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3184558.3191659</a></p></li></ul><h3 id="2019-KDD"><a href="#2019-KDD" class="headerlink" title="2019 KDD"></a>2019 KDD</h3><h5 id="paper-4"><a href="#paper-4" class="headerlink" title="paper"></a>paper</h5><ul><li><p><a href="https://www.kdd.org/kdd2019/accepted-papers/view/melu-meta-learned-user-preference-estimator-for-cold-start-recommendation" target="_blank" rel="noopener">MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation</a></p></li><li><p>Sequential Scenario-Specific Meta Learner for Online Recommendation</p><p><a href="https://www.kdd.org/kdd2019/accepted-papers/view/sequential-scenario-specific-meta-learner-for-online-recommendation" target="_blank" rel="noopener">https://www.kdd.org/kdd2019/accepted-papers/view/sequential-scenario-specific-meta-learner-for-online-recommendation</a></p></li><li><p>DAML: Dual Attention Mutual Learning between Ratings and Reviews for Item Recommendation</p><p><a href="https://www.kdd.org/kdd2019/accepted-papers/view/daml-dual-attention-mutual-learning-between-ratings-and-reviews-for-item-re" target="_blank" rel="noopener">https://www.kdd.org/kdd2019/accepted-papers/view/daml-dual-attention-mutual-learning-between-ratings-and-reviews-for-item-re</a></p></li></ul><h3 id="2018-KDD"><a href="#2018-KDD" class="headerlink" title="2018 KDD"></a>2018 KDD</h3><h5 id="paper-5"><a href="#paper-5" class="headerlink" title="paper"></a>paper</h5><h3 id="2020-AAAI"><a href="#2020-AAAI" class="headerlink" title="2020 AAAI"></a>2020 AAAI</h3><h5 id="paper-6"><a href="#paper-6" class="headerlink" title="paper"></a>paper</h5><ul><li>Multi-Feature Discrete Collaborative Filtering for Fast Cold-Start Recommendation</li></ul><h3 id="2019-AAAI"><a href="#2019-AAAI" class="headerlink" title="2019 AAAI"></a>2019 AAAI</h3><h5 id="paper-7"><a href="#paper-7" class="headerlink" title="paper"></a>paper</h5><ul><li>Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation System</li><li>From Zero-Shot Learning to Cold-Start Recommendation</li><li>HERS: Modeling Influential Contexts with Heterogeneous Relations for Sparse and Coldstart Recommendation</li></ul><h3 id="2018-AAAI"><a href="#2018-AAAI" class="headerlink" title="2018 AAAI"></a>2018 AAAI</h3><h5 id="paper-8"><a href="#paper-8" class="headerlink" title="paper"></a>paper</h5><ul><li><del>Coupled Poisson Factorization Integrated with User/Item Metadata for Modeling Popular and Sparse Ratings in Scalable Recommendation</del></li><li>Transferable Contextual Bandit for Cross-Domain Recommendation </li></ul><h3 id="2020-IJCAI"><a href="#2020-IJCAI" class="headerlink" title="2020 IJCAI"></a>2020 IJCAI</h3><h5 id="paper-9"><a href="#paper-9" class="headerlink" title="paper"></a>paper</h5><ul><li>Internal and Contextual Attention Network for Cold-start Multi-channel Matching in Recommendation</li><li>A Graphical and Attentional Framework for Dual-Target Cross-Domain Recommendation</li></ul><h3 id="2019-IJCAI"><a href="#2019-IJCAI" class="headerlink" title="2019 IJCAI"></a>2019 IJCAI</h3><ul><li>DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns    不是很相关</li></ul><h3 id="2018-IJCAI"><a href="#2018-IJCAI" class="headerlink" title="2018 IJCAI"></a>2018 IJCAI</h3><ul><li><p>A Deep Framework for Cross-Domain and Cross-System Recommendations</p><p><a href="https://arxiv.org/abs/2009.06215" target="_blank" rel="noopener">https://arxiv.org/abs/2009.06215</a></p></li></ul><h3 id="2020-SIGIR"><a href="#2020-SIGIR" class="headerlink" title="2020 SIGIR"></a>2020 SIGIR</h3><ul><li>Joint Training Capsule Network for Cold Start Recommendation</li><li>A Heterogeneous Graph Neural Model for Cold-Start Recommendation</li><li>AR-CF: Augmenting Virtual Users and Items in Collaborative Filtering for Addressing Cold-Start Problems</li><li>Content-aware Neural Hashing for Cold-start Recommendation</li><li>Recommending Podcasts for Cold-Start Users Based on Music Listening and Taste</li><li>CATN: Cross-Domain Recommendation for Cold-Start Users via Aspect Transfer Network</li></ul><h5 id="industry"><a href="#industry" class="headerlink" title="industry"></a>industry</h5><ul><li>A Heterogeneous Information Network based Cross Domain Insurance Recommendation System for Cold Start Users</li></ul><h3 id="2019-SIGIR"><a href="#2019-SIGIR" class="headerlink" title="2019 SIGIR"></a>2019 SIGIR</h3><ul><li><p>Warm Up Cold-start Advertisements: Improving CTR Predictions via Learning to Learn ID Embeddings</p></li><li><p>Deep Distribution Network: Addressing the Data Sparsity Issue for Top-N Recommendation</p><p><a href="https://dl.acm.org/doi/abs/10.1145/3331184.3331330" target="_blank" rel="noopener">https://dl.acm.org/doi/abs/10.1145/3331184.3331330</a></p></li></ul><h3 id="2020-RecSys"><a href="#2020-RecSys" class="headerlink" title="2020 RecSys"></a>2020 RecSys</h3><ul><li><p>The Embeddings That Came in From the Cold: Improving Vectors for New and Rare Products with Content-Based Inference</p><p><a href="https://dl.acm.org/doi/10.1145/3383313.3411477" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3383313.3411477</a></p></li></ul><h3 id="2019-RecSys"><a href="#2019-RecSys" class="headerlink" title="2019 RecSys"></a>2019 RecSys</h3><ul><li><p>Domain adaptation in display advertising: an application for partner cold-start</p><p><a href="https://dl.acm.org/doi/10.1145/3298689.3347004" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3298689.3347004</a></p></li><li><h5 id="CB2CF-a-neural-multiview-content-to-collaborative-filtering-model-for-completely-cold-item-recommendations"><a href="#CB2CF-a-neural-multiview-content-to-collaborative-filtering-model-for-completely-cold-item-recommendations" class="headerlink" title="CB2CF: a neural multiview content-to-collaborative filtering model for completely cold item recommendations"></a><a href="https://dl.acm.org/doi/10.1145/3298689.3347038" target="_blank" rel="noopener">CB2CF: a neural multiview content-to-collaborative filtering model for completely cold item recommendations</a></h5></li><li><h5 id="HybridSVD-when-collaborative-information-is-not-enough"><a href="#HybridSVD-when-collaborative-information-is-not-enough" class="headerlink" title="HybridSVD: when collaborative information is not enough"></a><a href="https://dl.acm.org/doi/10.1145/3298689.3347055" target="_blank" rel="noopener">HybridSVD: when collaborative information is not enough</a></h5></li></ul><h3 id="2018-RecSys"><a href="#2018-RecSys" class="headerlink" title="2018 RecSys"></a>2018 RecSys</h3><ul><li><h5 id="Preference-elicitation-as-an-optimization-problem"><a href="#Preference-elicitation-as-an-optimization-problem" class="headerlink" title="Preference elicitation as an optimization problem"></a><a href="https://dl.acm.org/doi/10.1145/3240323.3240352" target="_blank" rel="noopener">Preference elicitation as an optimization problem</a></h5></li><li><p>Spectral collaborative filtering</p><p><a href="https://dl.acm.org/doi/10.1145/3240323.3240343" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3240323.3240343</a></p></li><li><p>Psrec: social recommendation with pseudo ratings</p><p><a href="https://dl.acm.org/doi/10.1145/3240323.3240390" target="_blank" rel="noopener">https://dl.acm.org/doi/10.1145/3240323.3240390</a></p></li><li><h5 id="Adaptive-collaborative-topic-modeling-for-online-recommendation。"><a href="#Adaptive-collaborative-topic-modeling-for-online-recommendation。" class="headerlink" title="Adaptive collaborative topic modeling for online recommendation。"></a><a href="https://dl.acm.org/doi/10.1145/3240323.3240363" target="_blank" rel="noopener">Adaptive collaborative topic modeling for online recommendation</a>。</h5></li></ul><h3 id="2020-WSDM"><a href="#2020-WSDM" class="headerlink" title="2020 WSDM"></a>2020 WSDM</h3><h5 id="paper-10"><a href="#paper-10" class="headerlink" title="paper"></a>paper</h5><ul><li><p>DDTCDR: Deep Dual Transfer Cross Domain Recommendation</p><p><a href="https://dl.acm.org/doi/pdf/10.1145/3336191.3371793" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/3336191.3371793</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;keyword&quot;&gt;&lt;a href=&quot;#keyword&quot; class=&quot;headerlink&quot; title=&quot;keyword&quot;&gt;&lt;/a&gt;keyword&lt;/h5&gt;&lt;p&gt;&lt;em&gt;cold-start，cross domain， sparse&lt;/em&gt;&lt;/p&gt;
&lt;h3 i
      
    
    </summary>
    
    
      <category term="paper" scheme="https://hhh0hwz.github.io/categories/paper/"/>
    
    
      <category term="cold-start" scheme="https://hhh0hwz.github.io/tags/cold-start/"/>
    
  </entry>
  
  <entry>
    <title>python-argparse.ArgumentParser()</title>
    <link href="https://hhh0hwz.github.io/2020/09/20/python-argparse-ArgumentParser/"/>
    <id>https://hhh0hwz.github.io/2020/09/20/python-argparse-ArgumentParser/</id>
    <published>2020-09-20T10:35:46.000Z</published>
    <updated>2020-09-20T11:17:30.156Z</updated>
    
    <content type="html"><![CDATA[<h5 id="用法解析"><a href="#用法解析" class="headerlink" title="用法解析"></a>用法解析</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ap = argparse.ArgumentParser()</span><br></pre></td></tr></table></figure><p>argparse 是一个python模块：命令行选项，参数和子命令解析器</p><p>使用流程：</p><ul><li><p>创建解析器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(</span><br><span class="line">description=<span class="string">''</span>)</span><br></pre></td></tr></table></figure></li><li><p>添加参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">'--inner-batch'</span>, help=<span class="string">'inner batch size'</span>, choices=[<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>], default=<span class="number">5</span>, type=int,required=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>比如上面的’—inner-batch’，例如在启动程序demo.py时，在终端输入./demo.py —inner-batch 10 就会将inner-batch这个选项的参数设置为10，不给参数时使用default参数5。</p><p>type为参数类型，例如int。</p><p>choices用来选择输入参数的范围。</p><p>help用来描述这个选项的作用。</p><p>required用来设置在命令中显示参数，当required为True时，运行程序时在命令行里必须给出参数。</p></li><li><p>解析参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure><p>将属性给与args实例： 把parser中设置的所有”add_argument”给返回到args子类实例当中， 那么parser中增加的属性内容都会在args实例中，使用即可。</p></li><li></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;用法解析&quot;&gt;&lt;a href=&quot;#用法解析&quot; class=&quot;headerlink&quot; title=&quot;用法解析&quot;&gt;&lt;/a&gt;用法解析&lt;/h5&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;p
      
    
    </summary>
    
    
      <category term="python" scheme="https://hhh0hwz.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://hhh0hwz.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>LDA线性判别分析</title>
    <link href="https://hhh0hwz.github.io/2020/09/19/LDA%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/"/>
    <id>https://hhh0hwz.github.io/2020/09/19/LDA%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/</id>
    <published>2020-09-19T11:08:47.000Z</published>
    <updated>2020-09-20T08:01:34.069Z</updated>
    
    <content type="html"><![CDATA[<h3 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h3><p>LDA的思想是：<strong>最大化类间均值，最小化类内方差</strong>。意思是将数据投影到低维度上，并且投影后同种类数据的投影点尽可能的接近，不同种类的投影点的中心点尽可能的远。</p><p>参考：<a href="https://zhuanlan.zhihu.com/p/79696530" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79696530</a></p><p>假设样本有K类，每一类的样本的个数分别为$N_1,N_2,…,n_k$</p><p>$x_1^1,x_1^2,…,x_1^{N_1}$对应第1类</p><p>$x_2^1,x_2^2,…,x_2^{N_2}$对应第2类</p><p>$x_k^1,x_k^2,…,x_k^{N_k}$对应第K类，其中每个样本$x_i^j$均为$n$维向量</p><p>设$\hat{x_i^j}$为$x_i^j$变化后的样本，则$\hat{x_i^j}=<x,u>u=|x||u|cos\theta\cdot u=(x^Tu)u$</x,u></p><p>此处设$u$为单位向量，即$u^Tu=1$</p><p>假设第K类严格把你的数据集为$D_k$，变化后的样本<strong>均值</strong>为:</p><script type="math/tex; mode=display">\hat{m} = \frac{\sum_{\hat{x}\in D_k}{\hat{x}}}{N_k}</script><p>那么，第K类的样本<strong>方差</strong>为</p><script type="math/tex; mode=display">\frac{\sum_{\hat{x}\in D_k}(\hat x-\hat m)^T(\hat x-\hat m)}{N_k}</script><p>其中:</p><script type="math/tex; mode=display">\begin{aligned}\sum_{\hat{x}\in D_k}(\hat x-\hat m)^T(\hat x-\hat m)\\&=\sum_{x\in D_k}[(x^Tu)u-(m^Tu)u]^T[(x^Tu)u-(m^Tu)u]\\&=\sum_{x\in D_k}[(x^Tu)u^T-(m^Tu)u^T][(x^Tu)u-(m^Tu)u]\\&=\sum_{x\in D_k}[(x^Tu)^2u^Tu-2(x^Tu)(m^Tu)u^Tu+(m^Tu)^2u^Tu]\\&=\sum_{x\in D_k}[(x^Tu)^2-2(x^Tu)(m^Tu)+(m^Tu)^2]\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\frac{\sum_{\hat{x}\in D_k}(\hat x-\hat m)^T(\hat x-\hat m)}{N_k}\\&=\frac{\sum_{x\in D_k}(x^Tu)^2}{N_k}-2\frac{\sum_{x\in D_k}x^Tum^Tu}{N_k}+\frac{\sum_{x\in D_k}(m^Tu)^2}{N_k}\\&=\frac{\sum_{x\in D_k}u^Txx^Tu}{N_k}-2\frac{\sum_{x\in D_k}x^T}{N_k}um^Tu+(m^Tu)^2\\&注：\frac{\sum_{x\in D_k}(m^Tu)^2}{N_k}=(m^Tu)^2，因为m^Tu和x无关\\&=u^T\frac{\sum_{x\in D_k}xx^T}{N_k}u-(m^Tu)^2\\&注：\frac{\sum_{x\in D_k}x^T}{N_k}=m^T\\&=u^T(\frac{\sum_{x\in D_k}xx^T}{N_k}-mm^T)u\end{aligned}</script><p>各个类别的样本方差之和：</p><script type="math/tex; mode=display">\begin{aligned}\sum_k\frac{S_k}{N_k}&=\sum_{k=1}^{K}u^T(\frac{\sum_{x\in D_k}xx^T}{N_k}-m_km_k^T)u\\&=u^T\sum_{k=1}^{K}(\frac{\sum_{x\in D_k}xx^T}{N_k}-m_km_k^T)u\\&=u^TS_wu\end{aligned}</script><p>不同类别$i,j$之间的中心距离：</p><script type="math/tex; mode=display">\begin{aligned}S_{i,j}&=(\hat m_i-\hat m_j)^T(\hat m_i-\hat m_j)\\&=[(u^Tm_i)u-(u^Tm_j)u]^T[(m_iu^T)u-(m_ju^T)u]\\&=[(u^Tm_i)u^T-(u^Tm_j)u^T][(m_iu^T)u-(m_ju^T)u]\\&=u^T(m_i-m_j)u^Tu(m_i^T-m_j^T)u\\&=u^T(m_i-m_j)(m_i-m_j)^Tu\\\end{aligned}</script><p>所有类别之间的距离之和为：</p><script type="math/tex; mode=display">\begin{aligned}\sum_{i,j;i!=j}S_{i,j}&=u^T\sum_{i,j;i!=j}(m_i-m_j)(m_i-m_j)^Tu\\&=u^TS_bu\end{aligned}</script><p>LDA算法的目标是<strong>类间距离尽可能大，类内方差尽可能小</strong>，即最大化$u^TS_bu$，最小化$u^TS_wu$。</p><p>令<strong>$J(u)=\frac{u^TS_bu}{u^TS_wu}$</strong>，则目标函数为:</p><script type="math/tex; mode=display">max J(u)</script><p>为了使所求最大，可假设$u^TS_wu=1$，则问题转化成：</p><script type="math/tex; mode=display">max\ u^TS_bu\\s.t. \ \ u^TS_wu=1</script><script type="math/tex; mode=display">\begin{aligned}L(u,\lambda)&=u^tS_bu+\lambda(1-u^TS_wu)\\\frac{\partial L}{\partial u}&=S_bu+S_b^Tu-\lambda S_w u-\lambda S_w^T u\\&=2(S_bu-\lambda S_wu) \ \ \ \ \ \ S_b,S_w都是对称矩阵\\&=0    \Rightarrow S_bu=\lambda S_wu\end{aligned}</script><p>所以：$S_w^{-1}S_bu = \lambda u$</p><p>计算矩阵$S_w^{-1}S_b$的最大的d个特征值和d个特征向量$(w_1,w_2,…,w_d)$，得到投影矩阵$W=(w_1,w_2,…,w_d)$。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;LDA&quot;&gt;&lt;a href=&quot;#LDA&quot; class=&quot;headerlink&quot; title=&quot;LDA&quot;&gt;&lt;/a&gt;LDA&lt;/h3&gt;&lt;p&gt;LDA的思想是：&lt;strong&gt;最大化类间均值，最小化类内方差&lt;/strong&gt;。意思是将数据投影到低维度上，并且投影后同种类数据的
      
    
    </summary>
    
    
      <category term="回归" scheme="https://hhh0hwz.github.io/categories/%E5%9B%9E%E5%BD%92/"/>
    
    
      <category term="周志华" scheme="https://hhh0hwz.github.io/tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅笔记(1)</title>
    <link href="https://hhh0hwz.github.io/2020/09/18/%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://hhh0hwz.github.io/2020/09/18/%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-1/</id>
    <published>2020-09-18T07:57:36.000Z</published>
    <updated>2020-09-18T08:43:35.833Z</updated>
    
    <content type="html"><![CDATA[<h3 id="第一节课"><a href="#第一节课" class="headerlink" title="第一节课"></a>第一节课</h3><ul><li>机器学习就是自动找函式<ul><li>Regression: The output of the function is a <strong>scalar</strong></li><li>Binary Classification: Yes or No</li><li>Multi-class Classfication</li><li>Generation(生成):产生有结构的复杂东西</li></ul></li></ul><h3 id="第二节课"><a href="#第二节课" class="headerlink" title="第二节课"></a>第二节课</h3><h5 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h5><ul><li><p>Recommendation</p><p>$f(使用者A,商品B) = 购买可能性$</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;第一节课&quot;&gt;&lt;a href=&quot;#第一节课&quot; class=&quot;headerlink&quot; title=&quot;第一节课&quot;&gt;&lt;/a&gt;第一节课&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;机器学习就是自动找函式&lt;ul&gt;
&lt;li&gt;Regression: The output of the functi
      
    
    </summary>
    
    
      <category term="ML" scheme="https://hhh0hwz.github.io/categories/ML/"/>
    
    
      <category term="ML课程" scheme="https://hhh0hwz.github.io/tags/ML%E8%AF%BE%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>&#39;贝叶斯&#39;</title>
    <link href="https://hhh0hwz.github.io/2020/09/17/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>https://hhh0hwz.github.io/2020/09/17/%E8%B4%9D%E5%8F%B6%E6%96%AF/</id>
    <published>2020-09-17T10:28:41.000Z</published>
    <updated>2020-09-17T10:59:30.597Z</updated>
    
    <content type="html"><![CDATA[<h4 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h4><h5 id="贝叶斯的作用"><a href="#贝叶斯的作用" class="headerlink" title="贝叶斯的作用"></a>贝叶斯的作用</h5><ul><li>通过已知信息得到未知的概率<ul><li>在有限的信息下，能够帮助我们预测出概率</li></ul></li></ul><h5 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h5><ul><li>贝叶斯定理公式：</li></ul><script type="math/tex; mode=display">P(A|B) = P(A) \frac {P(B|A))}{P(B)}</script><p>其中$P(A)$是先验概率，即在不知道B事件发生的前提下，我们对A事件发生概率的一个主观判断。 </p><p>$P(B|A)/P(B)$是可能性函数，这是一个调整因子，即新信息事件B的发生调整，作用是使得先验概率更接近真实概率。</p><p>$P(A|B)$是后验概率，即在B事件发生后，我们对事件A概率的评估。</p><h5 id="贝叶斯定理的应用案例"><a href="#贝叶斯定理的应用案例" class="headerlink" title="贝叶斯定理的应用案例"></a>贝叶斯定理的应用案例</h5><ul><li><p>全概率公式</p><p>这公式的作用是计算贝叶斯定理中的P(B)</p><p>假设样本空间S，是事件A和事件A‘的和。有一事件B。</p><p>全概率公式：</p><script type="math/tex; mode=display">P(B) = P(B|A)P(A)+P(B|A')P(A')</script><p>它的含义是，如果A和A’组成一个问题的全部回答，那么事件B的概率，就等于A和A‘的概率分别乘以B对这两个事件的条件概率 之和。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;贝叶斯&quot;&gt;&lt;a href=&quot;#贝叶斯&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯&quot;&gt;&lt;/a&gt;贝叶斯&lt;/h4&gt;&lt;h5 id=&quot;贝叶斯的作用&quot;&gt;&lt;a href=&quot;#贝叶斯的作用&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯的作用&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="贝叶斯" scheme="https://hhh0hwz.github.io/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
    
      <category term="贝叶斯" scheme="https://hhh0hwz.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>Intro to RL</title>
    <link href="https://hhh0hwz.github.io/2020/07/27/Intro-to-RL/"/>
    <id>https://hhh0hwz.github.io/2020/07/27/Intro-to-RL/</id>
    <published>2020-07-27T11:17:35.000Z</published>
    <updated>2020-07-28T08:11:20.595Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-RL-problem"><a href="#The-RL-problem" class="headerlink" title="The RL problem"></a>The RL problem</h2><ul><li><p>the agent is to maximize the cumulative reward</p></li><li><p>An RL agent may include one or more of these components:policy/value function/Model </p><p>可以根据agent包括什么部分，来对RL算法进行划分</p></li></ul><h2 id="MDP"><a href="#MDP" class="headerlink" title="MDP"></a>MDP</h2><script type="math/tex; mode=display">(S,A,P,R,\gamma)</script><p>由上述五元组来表示</p><h2 id="Value-function"><a href="#Value-function" class="headerlink" title="Value function"></a>Value function</h2><p>和RL:Introduction 一书中讲的没啥区别</p><p>以及Policy $\pi$的定义</p><p>Optimal Value fucntion/Policy的定义基本是一样的</p><p>已经上述公式的Bellman形式，我的理解是用下一个递推式</p><h2 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h2><p>DP assumes full knowledge of MDP</p><ul><li><strong>Policy Evaluation</strong> （这里需要去看一下）<ul><li>Problem：对给定的策略得到值函数</li><li>Solution：iteration of Bellman Expectation backup</li></ul></li><li><strong>Policy Improvement</strong><ul><li>Problem：对给定的值函数得到策略</li></ul></li></ul><ul><li>Evaluation 和 improvement交替进行就是Iteration</li><li>那个很经典的图(2018sutton也是这么讲的)</li></ul><h2 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h2><ul><li><p>approximate the action-value function（用神经网络去拟合值函数）</p></li><li></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;The-RL-problem&quot;&gt;&lt;a href=&quot;#The-RL-problem&quot; class=&quot;headerlink&quot; title=&quot;The RL problem&quot;&gt;&lt;/a&gt;The RL problem&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the agent is 
      
    
    </summary>
    
    
      <category term="RLChina" scheme="https://hhh0hwz.github.io/categories/RLChina/"/>
    
    
      <category term="Intro" scheme="https://hhh0hwz.github.io/tags/Intro/"/>
    
  </entry>
  
  <entry>
    <title>cold-start problem paper</title>
    <link href="https://hhh0hwz.github.io/2020/07/07/cold-start-problem-paper/"/>
    <id>https://hhh0hwz.github.io/2020/07/07/cold-start-problem-paper/</id>
    <published>2020-07-07T09:39:56.000Z</published>
    <updated>2020-07-07T16:51:33.429Z</updated>
    
    <content type="html"><![CDATA[<p><strong>cold-start RS</strong> </p><p>RL for RS</p><p>RL for cold-start in RS</p><p>multi-arm Contextual Bandit</p><h2 id="2020-SIGIR"><a href="#2020-SIGIR" class="headerlink" title="2020 SIGIR"></a>2020 SIGIR</h2><h4 id="Cold-start-RS"><a href="#Cold-start-RS" class="headerlink" title="Cold-start RS"></a>Cold-start RS</h4><ul><li><p>Content-aware Neural Hashing for Cold-start Recommendation.</p></li><li><p><em>Recommending Podcasts for Cold-Start Users Based on Music Listening and Taste.</em></p></li><li><p>Recommendation for New Users and New Items via Randomized Training and Mixture-of-Experts Transformation.</p></li><li><p><strong>AR-CF: Augmenting Virtual Users and Items in Collaborative Filtering for Addressing Cold-Start Problems.</strong></p></li></ul><h4 id="RL-for-RS"><a href="#RL-for-RS" class="headerlink" title="RL for RS"></a>RL for RS</h4><ul><li><p>Self-Supervised Reinforcement Learning for Recommender Systems.</p></li><li><p>MaHRL: Multi-goals Abstraction based Deep Hierarchical Reinforcement Learning for Recommendations.</p></li><li><p><strong>Leveraging Demonstrations for Reinforcement Recommendation Reasoning over Knowledge Graphs.</strong></p></li></ul><h2 id="2020-KDD"><a href="#2020-KDD" class="headerlink" title="2020 KDD"></a>2020 KDD</h2><h4 id="Cold-start"><a href="#Cold-start" class="headerlink" title="Cold-start"></a>Cold-start</h4><ul><li><p>MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation</p><p><strong>Authors:</strong> Manqing Dong: University of New South Wales; Feng Yuan: University of New South Wales; Lina Yao: University of New South Wales; Xiwei Xu: Data 61; Liming Zhu: Data 61</p></li><li><p>Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation</p><p><strong>Authors:</strong> Yuanfu Lu: Beijing University of Posts and Telecommunications; Yuan Fang: Singapore Management University; Chuan Shi: Beijing University of Posts and Telecommunications</p></li></ul><h4 id="RL-KG"><a href="#RL-KG" class="headerlink" title="RL+KG"></a>RL+KG</h4><ul><li>Incremental Mobile User Profiling: Reinforcement Learning with Spatial Knowledge Graph for Modeling Event Streams<br><strong>Authors:</strong> Pengyang Wang: University of Central Florida; Kunpeng Liu: University of Central Florida; Lu Jiang: Northeast Normal University; Yanjie Fu: University of Central Florida; Xiaolin Li: Nanjing University</li><li></li></ul><h2 id="2020-WWW"><a href="#2020-WWW" class="headerlink" title="2020 WWW"></a>2020 WWW</h2><ul><li><p>Off-policy Learning in Two-stage Recommender Systems</p><p>Many real-world recommender systems need to be highly scalable: matching millions of items with billions of users, with milliseconds latency. The <strong>scalability</strong> requirement has led to widely used two-stage recommender systems, consisting of efficient candidate generation model(s) in the first stage and a more powerful ranking model in the second stage.</p><p>Logged user feedback, e.g., user clicks or dwell time, are often used to build both candidate generation and ranking models for recommender systems. While it’s easy to collect large amount of such data, they are inherently biased because the feedback can only be observed on items recommended by the previous systems. Recently, off-policy correction on such biases have attracted increasing interest in the field of recommender system research. However, most existing work either assumed that the recommender system is a single-stage system or only studied how to apply off-policy correction to the candidate generation stage of the system without explicitly considering the interactions between the two stages.</p><p>In this work, we propose a two-stage off-policy policy gradient method, and showcase that ignoring the interaction between the two stages leads to a sub-optimal policy in two-stage recommender systems. The proposed method explicitly takes into account the ranking model when training the candidate generation model, which helps improve the performance of the whole system. We conduct experiments on real-world datasets with large item space and demonstrate the effectiveness of our proposed method.</p></li><li><p>Hierarchical Adaptive Contextual Bandits for Resource Constraint based Recommendation</p><p>Contextual multi-armed bandit (MAB) achieves cutting-edge performance on a variety of problems. When it comes to real-world scenarios such as recommendation system and online advertising, however, it is essential to consider the resource consumption of exploration. In practice, there is typically non-zero cost associated with executing a recommendation (arm) in the environment, and hence, the policy should be learned with a fixed exploration cost constraint. It is challenging to learn a global optimal policy directly, since it is a NP-hard problem and significantly complicates the exploration and exploitation trade-off of bandit algorithms. Existing approaches focus on solving the problems by adopting the greedy policy which estimates the expected rewards and costs and uses a greedy selection based on each arm’s expected reward/cost ratio using historical observation until the exploration resource is exhausted. However, existing methods are hard to extend to infinite time horizon, since the learning process will be terminated when there is no more resource. In this paper, we propose a hierarchical adaptive contextual bandit method (HATCH) to conduct the policy learning of contextual bandits with a budget constraint. HATCH adopts an adaptive method to allocate the exploration resource based on the remaining resource/time and the estimation of reward distribution among different user contexts. In addition, we utilize full of contextual feature information to find the best personalized recommendation. Finally, in order to prove the theoretical guarantee, we present a regret bound analysis and prove that HATCH achieves a regret bound as low as . The experimental results demonstrate the effectiveness and efficiency of the proposed method on both synthetic data sets and the real-world applications.</p></li><li><p>Conversational Contextual Bandit: Algorithm and Application</p><p>Contextual bandit algorithms provide principled <strong>online learning</strong> solutions to balance the exploitation-exploration trade-off in various applications such as recommender systems. However, the learning speed of the traditional contextual bandit algorithms is often slow due to the need for extensive exploration. This poses a critical issue in applications like recommender systems, since users may need to provide feedbacks on a lot of uninterested items. To accelerate the learning speed, we generalize contextual bandit to conversational contextual bandit. Conversational contextual bandit leverages not only behavioral feedbacks on arms (e.g., articles in news recommendation), but also occasional conversational feedbacks on key-terms from the user. Here, a key-term can relate to a subset of arms, for example, a category of articles in news recommendation. We then design the Conversational UCB algorithm (ConUCB) to address two challenges in conversational contextual bandit: (1) which key-terms to select to conduct conversation, (2) how to leverage conversational feedbacks to accelerate the speed of bandit learning. We theoretically prove that ConUCB can achieve a smaller regret upper bound than the traditional contextual bandit algorithm LinUCB, which implies a faster learning speed. Experiments on synthetic data, as well as real datasets from Yelp and Toutiao, demonstrate the efficacy of the ConUCB algorithm.</p></li><li><p><strong>Learning from <em>Cross-Modal Behavior</em> Dynamics with Graph-Regularized Neural Contextual Bandit</strong></p><p>Contextual multi-armed bandit algorithms have received significant attention in modeling users’ preferences for <strong>online personalized recommender systems</strong> in a timely manner. While significant progress has been made along this direction, a few major challenges have not been well addressed yet: (i) a vast majority of the literature is based on linear models that cannot capture complex non-linear inter-dependencies of user-item interactions; (ii) existing literature mainly ignores the latent relations among users and non-recommended items: hence may not properly reflect users’ preferences in the real-world; (iii) current solutions are mainly based on historical data and are prone to cold-start problems for new users who have no interaction history.</p><p>To address the above challenges, we develop a Graph Regularized Cross-modal (GRC) learning model, a general framework to exploit transferable knowledge learned from user-item interactions as well as the external features of users and items in online personalized recommendations. In particular, the GRC framework leverage a non-linearity of neural network to model complex inherent structure of user-item interactions. We further augment GRC with the cooperation of the metric learning technique and a graph-constrained embedding module, to map the units from different dimensions (temporal, social and semantic) into the same latent space. An extensive set of experiments are conducted on two benchmark datasets as well as a large scale proprietary dataset from a major search engine demonstrates the power of the proposed GRC model in effectively capturing users’ dynamic preferences under different settings by outperforming all baselines by a large margin.</p></li></ul><h2 id="2020-ICML"><a href="#2020-ICML" class="headerlink" title="2020 ICML"></a>2020 ICML</h2><ul><li><p>Non-Stationary Bandits with Intermediate Observations</p><p>Online recommender systems </p></li><li><p>Stochastic bandits with arm-dependent delays</p></li></ul><h2 id="2019-NIPS"><a href="#2019-NIPS" class="headerlink" title="2019 NIPS"></a>2019 NIPS</h2><h4 id="RL-for-RS-1"><a href="#RL-for-RS-1" class="headerlink" title="RL for RS"></a>RL for RS</h4><ul><li><a href="http://papers.nips.cc/paper/9257-a-model-based-reinforcement-learning-with-adversarial-training-for-online-recommendation" target="_blank" rel="noopener">A Model-Based Reinforcement Learning with Adversarial Training for Online Recommendation</a> <a href="http://papers.nips.cc/author/xueying-bai-14275" target="_blank" rel="noopener">Xueying Bai</a>, <a href="http://papers.nips.cc/author/jian-guan-14276" target="_blank" rel="noopener">Jian Guan</a>, <a href="http://papers.nips.cc/author/hongning-wang-11803" target="_blank" rel="noopener">Hongning Wang</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;cold-start RS&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;RL for RS&lt;/p&gt;
&lt;p&gt;RL for cold-start in RS&lt;/p&gt;
&lt;p&gt;multi-arm Contextual Bandit&lt;/p&gt;
&lt;h2 id=&quot;2020-SIGIR
      
    
    </summary>
    
    
      <category term="survey" scheme="https://hhh0hwz.github.io/categories/survey/"/>
    
    
  </entry>
  
  <entry>
    <title>RL_survey</title>
    <link href="https://hhh0hwz.github.io/2020/06/28/RL-survey/"/>
    <id>https://hhh0hwz.github.io/2020/06/28/RL-survey/</id>
    <published>2020-06-28T06:45:47.000Z</published>
    <updated>2020-06-28T08:05:09.937Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2017-AAAI"><a href="#2017-AAAI" class="headerlink" title="2017 AAAI"></a>2017 AAAI</h2><h4 id="Machine-Learning-Applications"><a href="#Machine-Learning-Applications" class="headerlink" title="Machine Learning Applications"></a>Machine Learning Applications</h4><ul><li><p>Masamichi Shimosaka, Junichi Sato, Kazuhito Takenaka, Kentarou Hitomi: </p><p>Fast Inverse Reinforcement Learning with Interval Consistent Graph for Driving Behavior Prediction. 1532-1538</p></li><li><p>Kamil Andrzej Ciosek, Shimon Whiteson:<br>OFFER: Off-Environment Reinforcement Learning. 1819-1825</p></li><li><p>Carlo D’Eramo, Alessandro Nuara, Matteo Pirotta, Marcello Restelli:<br>Estimating the Maximum Expected Value in Continuous Reinforcement Learning Problems. 1840-1846</p></li><li><p>Salam El Bsat, Haitham Bou-Ammar, Matthew E. Taylor:<br>Scalable Multitask Policy Gradient Reinforcement Learning. 1847-1853</p></li><li><p>Aravind S. Lakshminarayanan, Sahil Sharma, Balaraman Ravindran:<br>Dynamic Action Repetition for Deep Reinforcement Learning. 2133-2139</p></li><li><p>Travis Mandel, Yun-En Liu, Emma Brunskill, Zoran Popovic:<br>Where to Add Actions in Human-in-the-Loop Reinforcement Learning. 2322-2328</p></li><li><p>Maxwell Svetlik, Matteo Leonetti, Jivko Sinapov, Rishi Shah, Nick Walker, Peter Stone:<br>Automatic Curriculum Graph Generation for Reinforcement Learning Agents. 2590-2596</p></li><li><p>Erik Talvitie:<br>Self-Correcting Models for Model-Based Reinforcement Learning. 2597-2603</p></li></ul><h4 id="Planning-and-Scheduling"><a href="#Planning-and-Scheduling" class="headerlink" title="Planning and Scheduling"></a>Planning and Scheduling</h4><ul><li><p>Zhuoru Li, Akshay Narayan, Tze-Yun Leong:<br>An Efficient Approach to Model-Based Hierarchical Reinforcement Learning. 3583-3589</p></li><li><p>Stuedent Abstracts<br>Rodrigo Cesar Bonini, Felipe Leno da Silva, Anna Helena Reali Costa:<br>Learning Options in Multiobjective Reinforcement Learning. 4907-4908</p></li><li><p>Ruben Glatt, Anna Helena Reali Costa:<br>Policy Reuse in Deep Reinforcement Learning. 4929-4930</p></li></ul><h2 id="2018-AAAI"><a href="#2018-AAAI" class="headerlink" title="2018 AAAI"></a>2018 AAAI</h2><ul><li><p>Yueh-Hua Wu, Shou-De Lin:<br>A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents. 1687-1694</p></li><li><p>Kristopher De Asis, J. Fernando Hernandez-Garcia, G. Zacharias Holland, Richard S. Sutton:<br>Multi-Step Reinforcement Learning: A Unifying Algorithm. 2902-2909</p></li><li><p>Udayan Khurana, Horst Samulowitz, Deepak S. Turaga:<br>Feature Engineering for Predictive Modeling Using Reinforcement Learning. 3407-3414</p></li><li><p>Lianmin Zheng, Jiacheng Yang, Han Cai, Ming Zhou, Weinan Zhang, Jun Wang, Yong Yu:<br>MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence. 8222-8223</p></li><li>a service of Schloss Dagstuhl - Leibniz Center for Informatics    homebrowsesearchabout<br>w3c valid html last updated on 2020-06-24 01:04 CEST by the dblp team</li></ul><h2 id="2019-AAAI"><a href="#2019-AAAI" class="headerlink" title="2019 AAAI"></a>2019 AAAI</h2><ul><li><p>Atanu R. Sinha, Deepali Jain, Nikhil Sheoran, Sopan Khosla, Reshmi Sasidharan:<br>Surveys without Questions: A Reinforcement Learning Approach. 257-264</p></li><li><p>Jing Zhang, Bowen Hao, Bo Chen, Cuiping Li, Hong Chen, Jimeng Sun:<br>Hierarchical Reinforcement Learning for Course Recommendation in MOOCs. 435-442<br>与推荐的结合？</p></li><li><p>Daoming Lyu, Fangkai Yang, Bo Liu, Steven Gustafson:<br>SDRL: Interpretable and Data-Efficient Deep Reinforcement Learning Leveraging Symbolic Planning. 2970-2977<br>可解释？</p></li><li><p>Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor:<br>How to Combine Tree-Search Methods in Reinforcement Learning. 3494-3501</p></li><li><p>Jing-Cheng Shi, Yang Yu, Qing Da, Shi-Yong Chen, Anxiang Zeng:<br>Virtual-Taobao: Virtualizing Real-World Online Retail Environment for Reinforcement Learning. 4902-4909</p></li><li><p>Silviu Pitis:<br>Rethinking the Discount Factor in Reinforcement Learning: A Decision Theoretic Approach. 7949-7956</p></li><li><p>Xiaoming Liu, Zhixiong Xu, Lei Cao, Xiliang Chen, Kai Kang:</p><p>Deep Reinforcement Learning via Past-Success Directed Exploration. 9979-9980</p></li><li><p>Rey Pocius, Lawrence Neal, Alan Fern:</p><p>Strategic Tasks for Explainable Reinforcement Learning. 10007-10008</p></li><li><p>Jacob Rafati, David C. Noelle:</p><p>Learning Representations in Model-Free Hierarchical Reinforcement Learning. 10009-10010</p></li></ul><h2 id="2020-AAAI"><a href="#2020-AAAI" class="headerlink" title="2020 AAAI"></a>2020 AAAI</h2><ul><li><p>Yaqing Wang, Weifeng Yang, Fenglong Ma, Jin Xu, Bin Zhong, Qiang Deng, Jing Gao:<br>Weak Supervision for Fake News Detection via Reinforcement Learning. 516-523</p></li><li><p>Wenjie Huang, Pham Viet Hai, William Benjamin Haskell:<br>Model and Reinforcement Learning for Markov Games with Risk Preferences. 2022-2029</p></li><li><p>Maor Gaon, Ronen I. Brafman:<br>Reinforcement Learning with Non-Markovian Rewards. 3980-3987</p></li><li><p>Guojia Wan, Bo Du, Shirui Pan, Gholamreza Haffari:<br>Reinforcement Learning Based Meta-Path Discovery in Large-Scale Heterogeneous Information Networks. 6094-6101</p></li><li><p>Min Yang, Chengming Li, Fei Sun, Zhou Zhao, Ying Shen, Chenglin Wu:<br>Be Relevant, Non-Redundant, and Timely: Deep Reinforcement Learning for Real-Time Event Summarization. 9410-9417</p></li><li><p>Prashan Madumal:<br>Explainable Agency in Reinforcement Learning Agents. 13724-13725</p></li></ul><h2 id="2017-NIPS"><a href="#2017-NIPS" class="headerlink" title="2017 NIPS"></a>2017 NIPS</h2><ul><li>Bridging the Gap Between Value and Policy Based Reinforcement Learning<br><a href="http://papers.nips.cc/paper/6870-bridging-the-gap-between-value-and-policy-based-reinforcement-learning" target="_blank" rel="noopener">http://papers.nips.cc/paper/6870-bridging-the-gap-between-value-and-policy-based-reinforcement-learning</a></li></ul><h2 id="2019-ICML"><a href="#2019-ICML" class="headerlink" title="2019 ICML"></a>2019 ICML</h2><ul><li><p>Generative Adversarial User Model for Reinforcement Learning Based Recommendation System In Time Series<br>Xinshi Chen · Shuang Li · Hui Li · Shaohua Jiang · Yuan Qi · Le Song</p></li><li><p>David Abel:<br>A Theory of State Abstraction for Reinforcement Learning. 9876-9877</p></li><li><p>Ana Valeria González-Garduño:</p><p>Reinforcement Learning for Improved Low Resource Dialogue Generation. 9884-9885</p></li><li><p>Abhinav Verma:<br>Verifiable and Interpretable Reinforcement Learning through Program Synthesis. 9902-9903</p></li><li><p>Ruohan Zhang:<br>Attention Guided Imitation Learning and Reinforcement Learning. 9906-9907</p></li></ul><h2 id="2019-NIPS"><a href="#2019-NIPS" class="headerlink" title="2019 NIPS"></a>2019 NIPS</h2><ul><li>Text-Based Interactive Recommendation via Constraint-Augmented Reinforcement Learning</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;2017-AAAI&quot;&gt;&lt;a href=&quot;#2017-AAAI&quot; class=&quot;headerlink&quot; title=&quot;2017 AAAI&quot;&gt;&lt;/a&gt;2017 AAAI&lt;/h2&gt;&lt;h4 id=&quot;Machine-Learning-Applications&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
      <category term="RL" scheme="https://hhh0hwz.github.io/categories/RL/"/>
    
    
      <category term="survey" scheme="https://hhh0hwz.github.io/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>arm汇编</title>
    <link href="https://hhh0hwz.github.io/2019/12/29/arm%E6%B1%87%E7%BC%96/"/>
    <id>https://hhh0hwz.github.io/2019/12/29/arm%E6%B1%87%E7%BC%96/</id>
    <published>2019-12-29T11:12:02.000Z</published>
    <updated>2019-12-29T12:18:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ARM"><a href="#ARM" class="headerlink" title="ARM"></a>ARM</h1><h3 id="V4"><a href="#V4" class="headerlink" title="V4"></a>V4</h3><ul><li><p>CMP r0,r1        比较r0和r1，r0-r1，并设置标志位</p></li><li><p>指令条件码</p><ul><li>EQ相等</li><li>NE不相等</li><li>HS无符号大于等于</li><li>LO无符号小于</li><li>HI无符号大于</li><li>LS无符号小于等于</li><li>GT大于</li><li>LE小于等于</li><li>GE大于等于</li><li>LT小于</li><li>MI为负</li><li>PL为正或零</li><li>VS溢出</li><li>VC无溢出</li></ul></li><li><p>ADD r0,r1,r2          r0=r1+r2</p></li><li><p>ADC r0,r1,r2          r0=r1+r2+C</p></li><li><p>SUB\SBC类似</p></li><li><p>RSB/RSC r0,r1,r2   r0=-(r1-r2)</p></li><li><p>AND\ORR\EOR\BIC</p></li><li><p>比较指令  CMP、CMN(r1-(-r2))</p></li><li><p>TST   用AND</p></li><li><p>TEQ  用EOR</p></li><li><p>移位 LSL、ASR、LSR、ROR、RXX</p></li><li><p>MUL r0,r1,r2      r0=r1*r2</p></li><li><p>MLA r0,r1,r2,r3      r0=r1*r2+r3</p></li><li><p>跳转 B{L}{<cond>} label</cond></p></li><li><p>LDR\STR</p><p>地址的块拷贝(1)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loop</span><br><span class="line">LDR r0,[r8],#4</span><br><span class="line">STR r0,[r10],#4</span><br><span class="line">CMP r8,r9</span><br><span class="line">BLT loop</span><br></pre></td></tr></table></figure><p>批量加载/存储</p><p>​    LDMIA/STMIA     inc after</p><p>​    LDMIB/STMIB     inc before</p><p>​    LDMDA                dec after</p><p>​    LDMDB                 dec before</p></li></ul><p>​      地址的块拷贝(2)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loop</span><br><span class="line">LDMIA r8!,&#123;r0-r7&#125;</span><br><span class="line">STMIA r10!,&#123;r0-r7&#125;</span><br><span class="line">CMP r8,r9</span><br><span class="line">BLT loop</span><br></pre></td></tr></table></figure><ul><li><p>SWP指令</p><p>用于在内存和寄存器之间传送一个字节和字的原子操作，先读取内存中数据到Rd，在将Rm中的数据写入到内存中</p></li><li><p>SWI软中断指令</p></li><li><p>程序状态寄存器的访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MSR r0,CPSR</span><br><span class="line">BIC r0,r0,#0x80</span><br><span class="line">MSR CPSR_c,r0   ;f,s,x,c,用户模式只能修改f</span><br></pre></td></tr></table></figure></li><li><p>STMFD/LDMFD 压栈，出栈</p></li></ul><h3 id="V5"><a href="#V5" class="headerlink" title="V5"></a>V5</h3><ul><li><p>CLZ{cond} rd,rm</p><p>返回rm中第一个1之前二进制0的个数</p></li><li><p>饱和运算</p><p>QSUB/QADD</p><p>QDSUB/QDADD</p></li><li><p>加载两个寄存器</p><p>LDR/STR{<cond>}D <Rd>, <addressing_mode></addressing_mode></Rd></cond></p></li></ul><h3 id="V6"><a href="#V6" class="headerlink" title="V6"></a>V6</h3><ul><li><p>REV 字节反转指令</p><p>将一个字内的字节反转</p></li></ul><h3 id="Thumb"><a href="#Thumb" class="headerlink" title="Thumb"></a>Thumb</h3><ul><li>B<cond> label 范围在+-256B</cond></li><li>B label  范围在+-2KB</li><li>BL label 范围在+-4MB</li><li>BX Rd  绝对跳转到Rd中的地址</li></ul><h3 id="Thumb-2"><a href="#Thumb-2" class="headerlink" title="Thumb-2"></a>Thumb-2</h3><ul><li><p>IT指令：使后面的一到四条指令为条件执行</p><p>ITTEE   EQ；IF-Then-Then-Else-Else</p></li></ul><h1 id="伪指令"><a href="#伪指令" class="headerlink" title="伪指令"></a>伪指令</h1><h3 id="段定义"><a href="#段定义" class="headerlink" title="段定义"></a>段定义</h3><p>AREA <name> {,&lt;属性&gt;} {,<READONLY readwrite>}</READONLY></name></p><h3 id="符号定义"><a href="#符号定义" class="headerlink" title="符号定义"></a>符号定义</h3><ul><li><p>定义全局变量</p><ul><li>GBLA 数字变量</li><li>GBLL 逻辑变量</li><li>GBLS 字符串变量</li></ul></li><li><p>定义局部变量</p><ul><li>LCLA</li><li>LCLL</li><li>LCLS</li></ul></li><li><p>变量赋值</p><ul><li><p>SETA</p><p>Test1   SETA   0XAA</p></li><li><p>SETL</p></li><li><p>SETS</p></li></ul></li><li><p>定义寄存器列表</p><p><name>  RLIST &lt;{list}&gt;</name></p></li></ul><h3 id="数据定义伪指令"><a href="#数据定义伪指令" class="headerlink" title="数据定义伪指令"></a>数据定义伪指令</h3><ul><li><p>DCB    字节</p><p>{<label>} DCB <expr></expr></label></p></li><li><p>DCW    半字</p></li><li><p>DCD     字</p></li><li><p>DCFD    double</p></li><li><p>DCFS     signal</p></li><li><p>DCQ      8字节</p></li><li><p>SPACE    空</p><p>DataSpace  SPACE 100</p></li><li><p>LTORG</p><p>用来说明后面的某个存储区域为一个用来暂时存储数据的数据缓冲区</p></li><li><p>FIELD 和 MAP 用来定义结构化的内存表</p><p>​    MAP 0X100 ；定义结构化内存表首地址为0X100<br>​    A FIELD 16 ；定义A的长度为16字节，位置为0X100<br>​    B FIELD 32 ；定义B的长度为32字节，位置为0X110<br>​    S FIELD 256 ；定义S的长度为256字节，位置为0X130</p></li></ul><h3 id="其他常用的伪指令"><a href="#其他常用的伪指令" class="headerlink" title="其他常用的伪指令"></a>其他常用的伪指令</h3><ul><li><p>ALIGN 对齐方式</p></li><li><p>ENTRY</p></li><li><p>END</p></li><li><p>EQU</p><p>Test EQU 50   ；定义标号Test的值为50<br>Addr EQU 0x55, CODE32 ；定义Addr的值为0x55，且该处为32位的ARM指令</p></li><li><p>EXPORT 声明外部可引用</p></li><li><p>IMPORT/EXTERN 引用外部的符号</p></li><li><p>GET/INCLUDE</p><p>将一个源文件包含到当前的源文件，并将被包含的源文件在当前位置进行汇编</p></li><li><p>RN 给寄存器起别名</p></li></ul><h3 id="arm宏"><a href="#arm宏" class="headerlink" title="arm宏"></a>arm宏</h3><ul><li><p>MARCO 和 MEND</p><p>可以为一段程序段定义一个名称，这样，在汇编语言应用程序中可以通过这个名称来使用它代表的程序段。</p></li></ul><h3 id="宏指令"><a href="#宏指令" class="headerlink" title="宏指令"></a>宏指令</h3><ul><li><p>ADR</p><p>ADR <reg>,<expr></expr></reg></p><p>将一个近地址值传到一个寄存器中</p></li><li><p>ADRL   远地址，只能在ARM状态下使用</p></li><li><p>LDR 全范围地址</p></li><li><p>NOP 空指令</p></li></ul><h3 id="else"><a href="#else" class="headerlink" title="else"></a>else</h3><ul><li><p>跳转表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">MOV R0,N</span><br><span class="line">ADR R5,JPTAB</span><br><span class="line">LDR PC,[R5,R0,LSL #2]</span><br><span class="line">JPTAB</span><br><span class="line">DCD FUN0</span><br><span class="line">DCD FUN1</span><br><span class="line">DCD FUN2</span><br><span class="line">FUN0 ……</span><br><span class="line">FUN1 ……</span><br><span class="line">FUN2 ……</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ARM&quot;&gt;&lt;a href=&quot;#ARM&quot; class=&quot;headerlink&quot; title=&quot;ARM&quot;&gt;&lt;/a&gt;ARM&lt;/h1&gt;&lt;h3 id=&quot;V4&quot;&gt;&lt;a href=&quot;#V4&quot; class=&quot;headerlink&quot; title=&quot;V4&quot;&gt;&lt;/a&gt;V4&lt;/h3&gt;&lt;u
      
    
    </summary>
    
    
      <category term="ARM" scheme="https://hhh0hwz.github.io/categories/ARM/"/>
    
    
      <category term="ARM" scheme="https://hhh0hwz.github.io/tags/ARM/"/>
    
  </entry>
  
  <entry>
    <title>pytorch</title>
    <link href="https://hhh0hwz.github.io/2019/12/12/pytorch/"/>
    <id>https://hhh0hwz.github.io/2019/12/12/pytorch/</id>
    <published>2019-12-12T11:29:12.000Z</published>
    <updated>2019-12-12T11:29:14.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>SGD</title>
    <link href="https://hhh0hwz.github.io/2019/12/05/SGD/"/>
    <id>https://hhh0hwz.github.io/2019/12/05/SGD/</id>
    <published>2019-12-05T04:28:37.000Z</published>
    <updated>2019-12-06T01:46:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>大多数机器学习或者深度学习算法都涉及某种形式的优化。优化指的是改变$x$以最大化或者最小化$f(x)$的任务。</p><p>我们把要最小化或最大化的函数成为目标函数或者准则。当我们对其进行最小化时，我们也把它称为<strong>代价函数、损失函数或者误差函数</strong>。</p><p>假设一个损失函数为：</p><script type="math/tex; mode=display">J(\theta) = 1/2\sum_{i=1}^{m}(h_{\theta}(x)-y)^2</script><p>其中$h_{\theta(x)} = \theta_0+ \theta_1x_1+…+\theta_n x_n$ ,然后要最小化它。</p><p><strong>梯度下降：</strong>我们知道曲面上方向导数的最大值的方向就代表了梯度的方向，因此我们在做梯度下降的时候，应该是沿着梯度的反方向进行权重的更新，可以有效的找到全局的最优解。这个的更新过程可以描述为：</p><script type="math/tex; mode=display">\begin{align}\theta_j &= \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta)\\\frac{\partial}{\partial\theta_j}J(\theta) &= \frac{\partial}{\partial\theta_j}\frac{1}{2}(h_{\theta}(x)-y)^2\\&= 2*\frac{1}{2}(h_{\theta}(x)-y)\cdot\frac{\partial}{\partial\theta_j}(\sum_{i=0}^{n}\theta_ix_i-y)\\&= (h_{\theta}(x)-y)x_j\end{align}</script><p>其中，$\alpha$ 是学习率。</p><h4 id="拓展为随机梯度下降"><a href="#拓展为随机梯度下降" class="headerlink" title="拓展为随机梯度下降"></a>拓展为随机梯度下降</h4><ul><li><p>批量梯度下降：<u>在每次更新时用所有样本</u>，要留意，在梯度下降中，对于$\theta_i$的更新，所有的样本都有贡献。其计算得到的是一个标准梯度，对于最优化问题，凸问题，也肯定可以达到一个全局最优。因而理论上来说一次更新的幅度是比较大的。如果样本不多的情况下，当然是这样收敛的速度会更快啦。但是很多时候，样本很多，更新一次要很久，这样的方法就不合适啦。下图是其更新公式</p><script type="math/tex; mode=display">\theta_j = \theta_j+\alpha\sum_{i=1}^{m}(y^{(i)}-h_{\theta}(x^{(i)}))x_j^{(i)},(\ for\ every\ j\ )</script></li><li><p>随机梯度下降：<u>在每次更新时用1个样本</u>，可以看到多了随机两个字，随机也就是说我们用样本中的一个例子来近似我所有的样本，来调整$\theta$ ，因而随机梯度下降是会带来一定的问题，因为计算得到的并不是准确的一个梯度，对于最优化问题，凸问题，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。但是相比于批量梯度，这样的方法更快，更快收敛，虽然不是全局最优，但很多时候是我们可以接受的，所以这个方法用的也比上面的多。下图是其更新公式：</p><p>for i = 1 to m : </p><script type="math/tex; mode=display">\theta_j = \theta_j+\alpha\sum_{i=1}^{m}(y^{(i)}-h_{\theta}(x^{(i)}))x_j^{(i)},(\ for\ every\ j\ )</script></li><li><p>mini-batch梯度下降：<u>在每次更新时用b个样本</u>，其实批量的梯度下降就是一种折中的方法，他用了一些小样本来近似全部的，其本质就是我1个指不定不太准，那我用个30个50个样本那比随机的要准不少了吧，而且批量的话还是非常可以反映样本的一个分布情况的。在深度学习中，这种方法用的是最多的，因为这个方法收敛也不会很慢，收敛的局部最优也是更多的可以接受！</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;随机梯度下降&quot;&gt;&lt;a href=&quot;#随机梯度下降&quot; class=&quot;headerlink&quot; title=&quot;随机梯度下降&quot;&gt;&lt;/a&gt;随机梯度下降&lt;/h2&gt;&lt;h4 id=&quot;梯度下降&quot;&gt;&lt;a href=&quot;#梯度下降&quot; class=&quot;headerlink&quot; title=&quot;梯
      
    
    </summary>
    
    
      <category term="梯度下降" scheme="https://hhh0hwz.github.io/categories/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
    
      <category term="SGD" scheme="https://hhh0hwz.github.io/tags/SGD/"/>
    
  </entry>
  
  <entry>
    <title>transE code 笔记</title>
    <link href="https://hhh0hwz.github.io/2019/12/05/transE-code-%E7%AC%94%E8%AE%B0/"/>
    <id>https://hhh0hwz.github.io/2019/12/05/transE-code-%E7%AC%94%E8%AE%B0/</id>
    <published>2019-12-05T04:20:29.000Z</published>
    <updated>2019-12-06T13:29:32.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p><strong>random</strong></p><ul><li><p>sample 函数</p><p>功能：从序列中随机抽取n个元素，并将这个n个元素以list的形式返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint, sample</span><br><span class="line">date = [randint(<span class="number">10</span>,<span class="number">20</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line">c = sample(date, <span class="number">5</span>)</span><br><span class="line">print(c)</span><br><span class="line"><span class="comment"># 输出：[12, 17, 10, 12, 17]</span></span><br><span class="line"><span class="comment"># randint(10,20) for _ in range(10)：从10~20间随机抽取10个数；</span></span><br></pre></td></tr></table></figure></li><li><p>uniform 函数</p><p>功能：随机生成下一个实数，它在 [x, y] 范围内。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.uniform(x, y)</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p><strong>math</strong></p><ul><li><p>fabs函数</p><p>功能：返回数字的绝对值</p></li></ul></li><li><p><strong>numpy</strong></p><ul><li><p>norm</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> norm</span><br><span class="line">var = norm(list)</span><br><span class="line"><span class="comment">#得到的结果是所有元素平方和的平方根</span></span><br></pre></td></tr></table></figure></li><li><p>mat </p><p>功能：创建矩阵matrix</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from numpy import *</span><br><span class="line">matA &#x3D; mat(list)</span><br></pre></td></tr></table></figure></li><li><p>cov</p><p>功能：协方差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.cov(m, y=<span class="literal">None</span>, rowvar=<span class="literal">True</span>, bias=<span class="literal">False</span>, ddof=<span class="literal">None</span>, fweights=<span class="literal">None</span>, aweights=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数见:<a href="https://blog.csdn.net/zhuzuwei/article/details/77848323" target="_blank" rel="noopener">https://blog.csdn.net/zhuzuwei/article/details/77848323</a></p></li><li><p>numpy.linalg.eig()</p><p>功能：计算矩阵的特征值和特征向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</span><br><span class="line">w,v = linalg.eig(np.diag((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)))</span><br></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;random&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;sample 函数&lt;/p&gt;
&lt;p&gt;功能：从序列中随机抽取n个元素，并将这个n个元素以list的形式返回。&lt;/p&gt;
&lt;figure class=&quot;highlight python
      
    
    </summary>
    
    
      <category term="python" scheme="https://hhh0hwz.github.io/categories/python/"/>
    
    
      <category term="random" scheme="https://hhh0hwz.github.io/tags/random/"/>
    
      <category term="math" scheme="https://hhh0hwz.github.io/tags/math/"/>
    
      <category term="numpy" scheme="https://hhh0hwz.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>SVM</title>
    <link href="https://hhh0hwz.github.io/2019/12/04/SVM/"/>
    <id>https://hhh0hwz.github.io/2019/12/04/SVM/</id>
    <published>2019-12-04T11:54:09.000Z</published>
    <updated>2019-12-07T03:41:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="了解SVM"><a href="#了解SVM" class="headerlink" title="了解SVM"></a>了解SVM</h2><p>支持向量机(support vector machine)，是一种二分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</p><h4 id="1-1-logistic-回归"><a href="#1-1-logistic-回归" class="headerlink" title="1.1 logistic 回归"></a>1.1 logistic 回归</h4><p>线性分类器：</p><p>​    给定一些数据点，分别属于不同的类，现在要找到一个线性分类器把这些数据分成两类。如果用x表示数据点，用y表示类别，一个线性分类器的学习目标就是在n维数据空间中找到一个超平面。</p><p><em>超平面：n维欧式空间中余维度等于1的线性子空间，也就是(n-1)维空间。比如平面中的直线，空间中的平面。因为超平面是线性子空间，所以其一定过原点。原因：子平面要包含零向量。</em></p><p>超平面的方程：</p><script type="math/tex; mode=display">w^Tx+b = 0</script><p>logistic 回归的目的是从特征中学习一个0/1分类的模型，将自变量取值的负无穷到正无穷映射到(0,1)上，映射后的值表示y=1的概率。logistic 函数如下：</p><script type="math/tex; mode=display">h_{\theta}(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}}</script><p>其中，x是n维特征向量，函数g就是logistic 函数。</p><p>从而</p><script type="math/tex; mode=display">P(y=1|x;\theta) = h_{\theta}(x)\\P(y=0|x;\theta) = 1 - h_{\theta}(x)</script><p>当我要判别一个新来的特征属于哪个类时，只需要看$h_{\theta}(x)$的值就可以了。</p><p>$\theta^Tx=\theta_0+\theta_1x_1+…+\theta_n x_n$ 中的$\theta_0$ 替换成b，$\theta_1x_1+…+\theta_n x_n$ 替换成$w^T x$ 就可以发现线性分类器的超平面方程和logistic 回归很相似。</p><p>对logistic做一个简单的总结：</p><script type="math/tex; mode=display">g(z)=\begin{cases}1,& \text{z>=0}\\-1,& \text{z<0}\end{cases}</script><h4 id="1-2-函数间隔-functional-margin-与几何间隔-Geometrical-margin"><a href="#1-2-函数间隔-functional-margin-与几何间隔-Geometrical-margin" class="headerlink" title="1.2 函数间隔(functional margin)与几何间隔(Geometrical margin)"></a>1.2 函数间隔(functional margin)与几何间隔(Geometrical margin)</h4><p>在超平面$w<em>x+b=0$确定的情况下，$|w</em>x+b|$ 的大小可以确定点x距离直线的远近。<strong>还可以通过判断$w*x+b$和y的符号来判断分类是否正确</strong> ，所以用$y(w*x+b)$ 的正负性来表示分类是否正确。</p><p>定义函数间隔用$\hat{\gamma}$ :</p><script type="math/tex; mode=display">\hat{\gamma} = y(w^Tx+b) = y*f(x)</script><p>样本数据所有的样本点$(x_i,y_i)$ 的函数间隔的最小值，即为超平面对该训练集的<strong>函数间隔</strong></p><p>根据下图和平面几何的知识，</p><p><img src="/2019/12/04/SVM/geometric_margin.png" alt></p><p>可以得出：</p><script type="math/tex; mode=display">x=x_0+\gamma \frac{w}{|w|}</script><p>其中$\frac{w}{|w|}$是单位向量，因为$w^Tx_0+b=0$ 和$w^t w=|w|^2$ ，所以$\gamma$：</p><script type="math/tex; mode=display">{\gamma} = \frac{w^Tx+b}{|w|} = \frac{f(x)}{|w|}</script><p>几何间隔的定义式如下：</p><script type="math/tex; mode=display">\tilde{\gamma} = y\gamma = \frac{\hat{\gamma}}{|w|}</script><p>因为函数间隔会随着(w,b)等比例增大而增大，而几何间隔不会，因此我们后文使用的都是几何间隔。</p><h4 id="1-3-Maximum-Margin-Classifier"><a href="#1-3-Maximum-Margin-Classifier" class="headerlink" title="1.3 Maximum Margin Classifier"></a>1.3 Maximum Margin Classifier</h4><p>最大间隔分类器目标函数定义为：$max\  \tilde{\gamma}$</p><p>同时需要满足一些条件，根据间隔的定义：$\gamma_i&gt;=\gamma,i=1,….n$ </p><p>因为函数间隔可以根据(w,b)同比例变化，所以可以将其假设为1，那么上述的目标函数就转化成了：</p><script type="math/tex; mode=display">max \frac{1}{|w|},\ \ s.t.,y_i(w^Tx_i+b)>=1,i=1,...n</script><p>后面的相当于加了一个约束条件。(关于为什么函数间隔设置为1，<a href="https://blog.csdn.net/lw_power/article/details/82940105这里给出了一个有趣的证明" target="_blank" rel="noopener">https://blog.csdn.net/lw_power/article/details/82940105这里给出了一个有趣的证明</a>)</p><p><img src="/2019/12/04/SVM/svm1.png" style="zoom:35%;"></p><p>如上图所示，中间的实线便是寻找的最优超平面的解；虚线上间隔边界上的点则是<strong>支持向量</strong>。显然不是支持向量的点都满足$y_i(w^Tx_i+b)&gt;=1$</p><h2 id="深入SVM"><a href="#深入SVM" class="headerlink" title="深入SVM"></a>深入SVM</h2><h4 id="2-1从线性可分到不可分"><a href="#2-1从线性可分到不可分" class="headerlink" title="2.1从线性可分到不可分"></a>2.1从线性可分到不可分</h4><p>之前的目标函数:</p><script type="math/tex; mode=display">max\frac{1}{|w|}\ \ s.t.,y_i(w^Tx_i+b)\geq1,i=1,...,n</script><p>显然等价于下面的问题</p><script type="math/tex; mode=display">min\frac{1}{2}|w|^2\ \ s.t.,y_i(w^Tx_i+b)\geq1,i=1,...,n</script><p>可以使用拉格朗日对偶性求界上述问题，简单地说，通过给每一个学术条件加上一个拉格朗日乘子$\alpha$ ，定义拉格朗日函数，通过拉格朗日函数将约束条件融合到目标函数中，从而只用一个函数表达式便能清楚的表达出上述的式子。</p><script type="math/tex; mode=display">\mathcal{L}(w,b,\alpha)=\frac{1}{2}|w|^2-\sum_{i=1}^{n}\alpha_i(y_i(w^Tx_i+b)-1)</script><p>然后令</p><script type="math/tex; mode=display">\theta(w) = \mathop{max}_{a_i\geq0}\mathcal{L}(w,b,\alpha)</script><p>容易验证，当约束条件不满足的时候，$\theta(w)$都趋近于无穷大。例如$y_i(w^Tx_i+b)&lt;1$ ，$\alpha_i$趋向于正无穷的时候，函数值趋近于无穷大。</p><p><strong>所以在满足约束条件的情况下，$\theta(w)$和原函数等价。</strong></p><p>所以目标函数等价于:</p><script type="math/tex; mode=display">\mathop{min}_{w,b}\theta(w) = \mathop{min}_{w,b}\mathop{max}_{\alpha_i\geq0}\mathcal{L}(w,b,\alpha)</script><p>用$p^{*}$表示这个问题的最优值。</p><p>上述问题的对偶问题是:</p><script type="math/tex; mode=display">\mathop{max}_{\alpha_i\geq0}\mathop{min}_{w,b}\mathcal{L}(w,b,a) = d^*</script><p>可以证明$d^<em> \leq p^</em>$,在某些条件下，两者相等，就可以使用对偶问题求解原始问题了。</p><p>这里的某些条件指的是KTT条件：</p><p>假设$w^<em>,b^</em>,\alpha^<em>$是$d^</em>=p^*$时，对应的最优解。</p><ul><li>对各参数的偏导为0。</li><li>各约束条件满足</li></ul><p><del>这里不太懂</del></p><p>对偶问题求解步骤：</p><ul><li><p>固定$\alpha$，让$\mathcal{L}$关于$w$和$b$最小化，对$w$和$b$求偏导：</p><script type="math/tex; mode=display">\begin{align}&\frac{\partial\mathcal{L}}{\partial w} = 0\Longrightarrow w-\sum_{i=1}^{n}\alpha_iy_ix_i=0 \\&\frac{\partial\mathcal{L}}{\partial b} = 0 \Longrightarrow \sum_{i=1}^{n}\alpha_iy_i = 0\end{align}</script><p>带入之前的$\mathcal{L}$中：</p><script type="math/tex; mode=display">\begin{align}\mathcal{L}(w,b,\alpha) &= \frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_jy_iy_jx_ix_j - \sum_{i,j=1}^{n}\alpha_i\alpha_jy_iy_jx_ix_j - b\sum_{i=1}^{n}\alpha_iy_i+\sum_{i=1}^{n}\alpha_i \\&=\sum_{i=1}^{n}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_jy_iy_jx_ix_j\end{align}</script></li><li><p>很明显可以看出来，$\mathcal{L}$中已经没有$w,b$了，于是对$\alpha$求极大</p><script type="math/tex; mode=display">\mathop{max}_{\alpha}\sum_{i=1}^{n}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_jy_iy_jx_ix_j\\s.t., \alpha_i \geq 0,i=1,...n\\\sum_{i=1}^{n}\alpha_iy_i = 0</script><p>只要求出来$\alpha$，其他的参数也就可以求出来了</p></li><li><p>最后一步，利用<strong>SMO算法</strong>求解对偶问题中的拉格朗日乘子$\alpha$</p></li></ul><p><strong>线性不可分的情况：</strong></p><p>最初的超平面方程：</p><script type="math/tex; mode=display">f(x) = w^Tx + b</script><p>可以写成:</p><script type="math/tex; mode=display">\begin{align}f(x) &= (\sum_{i=1}^{n}\alpha_iy_ix_i)^Tx+b\\&= \sum_{i=1}^{n}\alpha_iy_i<x_i,x>+b\end{align}</script><p>对于新点x的预测，只需要计算它与训练数据点的内积即可。</p><h4 id="2-2-kernel函数"><a href="#2-2-kernel函数" class="headerlink" title="2.2 kernel函数"></a>2.2 kernel函数</h4><p>为了可以处理线性不可分的情况，引入kernel函数。将原始数据映射到高维空间，来解决在原始空间中线性不可分的问题。</p><ul><li><p>举个例子</p><p><img src="/2019/12/04/SVM/svm2.png" alt></p></li></ul><p>上图的数据，一个理想的分界线应该是一个圆圈，而不是一个超平面(线)。如果用$X_1$和$X_2$来表示这个二维平面的两个坐标的话，我们知道一条二次曲线的方程可以写做:</p><script type="math/tex; mode=display">a_1X_1+a_2X_1^2+a_3X_2+a_4X_2^2+a_5X_1X_2+a_6 = 0</script><p>如果构造一个五维空间，五个坐标值分别是$Z_1 = X_1,Z_2=X_1^2,Z_3=X_2,Z_4 = X_2^2,Z_5=X_1X_2$，那么显然，上面方程在新坐标系下可以写成:</p><script type="math/tex; mode=display">\sum_{i=1}^{5}a_iZ_i+a_6 = 0</script><p>很明显可以看出，关于新坐标Z，这正是一个超平面方程。将X映射到高维空间中，就可以将数据变为线性可分的，这就是kernel函数的核心思想。</p><p>kernel函数相当于把:</p><script type="math/tex; mode=display">f(x) = \sum_{i=1}^{n}\alpha_iy_i<x_i,x>+b</script><p>映射成:</p><script type="math/tex; mode=display">f(x) = \sum_{i=1}^{n}\alpha_iy_i<\phi(x_i),\phi(x)></script><p>其中$\alpha$可以通过求解dual问题得到:</p><script type="math/tex; mode=display">\mathop{max}_{\alpha}\sum_{i=1}^{n}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_jy_iy_j\phi(x_i)\phi(x_j)\\s.t., \alpha_i \geq 0,i=1,...n\\\sum_{i=1}^{n}\alpha_iy_i = 0</script><p>但是发现，对于二维空间做映射，新空间的维度是5；如果原始空间是3维，那么新空间是19维的。这显然是无法接受的。</p><p>所以kernel函数的巧妙之处就出现了。</p><p><strong>kernel可以避免在高维度空间中进行计算，而在低维空间中进行运算。</strong></p><h4 id="2-3-使用松弛变量处理-outliers"><a href="#2-3-使用松弛变量处理-outliers" class="headerlink" title="2.3 使用松弛变量处理 outliers"></a>2.3 使用松弛变量处理 outliers</h4><p>outliers是指下图的黑色线圈出来的蓝色点这样的数据。</p><p><img src="/2019/12/04/SVM/svm3.png" style="zoom:50%;"></p><p>因为这样的点存在，使得超平面存在较大的误差。 为了处理这种情况，SVM 允许数据点在一定程度上偏离一下超平面。例如上图中，黑色实线所对应的距离，就是该 outlier 偏离的距离，如果把它移动回来，就刚好落在原来的 超平面 蓝色间隔边界上，而不会使得超平面发生变形了。</p><p>只需要将原本的约束条件:</p><script type="math/tex; mode=display">y_i(w^Tx_i+b)\geq 1,i=1,...,n</script><p>修改成:</p><script type="math/tex; mode=display">y_i(w^Tx_i+b)\geq1-\xi,i=1,...,n</script><p>其中$\xi \geq0$称为松弛变量。对应允许$x_i$偏离function margin的距离。如果$\xi$任意大的话，那么所有的超平面都满足条件了。所以我们对$\xi$进行正则化。</p><script type="math/tex; mode=display">min\frac{1}{2}|w|^2+C\sum_{i=1}^n\xi_i</script><p> 其中C是一个实现固定的值，用于控制目标函数中两项(“寻找margin最大的超平面”和“保证数据点偏差量最大”)之间的权重。</p><p>得到新的损失函数：</p><script type="math/tex; mode=display">\mathcal{L}(w,b,\xi,\alpha,r) = \frac{1}{2}|w|^2+C\sum_{i=1}^n\xi-\sum_{i=1}^{n}\alpha_i(y_i(w^Tx_i+b)-1+\xi)-\sum_{i=1}^nr_i\xi_i</script><p>分析方法和前面一样，先对$\xi,w,b$求导：</p><script type="math/tex; mode=display">\begin{align}&\frac{\partial\mathcal{L}}{\partial w} = 0 \Longrightarrow w=\sum_{i=1}^n\alpha_iy_ix_i \\&\frac{\partial\mathcal{L}}{\partial b} = 0 \Longrightarrow \sum_{i=1}^{n}\alpha_iy_i=0\\&\frac{\partial\mathcal{L}}{\partial \xi} = 0 \Longrightarrow C-\alpha_i-r_i =0,i=1,...,n\end{align}</script><p>将上式带回$\mathcal{L}$中，</p><script type="math/tex; mode=display">\mathop{max}_{\alpha}\sum_{i=1}^{n}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_jy_iy_j\phi(x_i)\phi(x_j)\\s.t., 0\leq \alpha_i \leq C,i=1,...n\\\sum_{i=1}^{n}\alpha_iy_i = 0</script><h2 id="证明SVM"><a href="#证明SVM" class="headerlink" title="证明SVM"></a>证明SVM</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;了解SVM&quot;&gt;&lt;a href=&quot;#了解SVM&quot; class=&quot;headerlink&quot; title=&quot;了解SVM&quot;&gt;&lt;/a&gt;了解SVM&lt;/h2&gt;&lt;p&gt;支持向量机(support vector machine)，是一种二分类模型，其基本模型定义为特征空间上的间隔最大的
      
    
    </summary>
    
    
      <category term="分类" scheme="https://hhh0hwz.github.io/categories/%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="二分类" scheme="https://hhh0hwz.github.io/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/"/>
    
      <category term="SVM" scheme="https://hhh0hwz.github.io/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>FM(factorization machine)</title>
    <link href="https://hhh0hwz.github.io/2019/12/04/FM-factorization-machine/"/>
    <id>https://hhh0hwz.github.io/2019/12/04/FM-factorization-machine/</id>
    <published>2019-12-04T02:58:10.000Z</published>
    <updated>2019-12-05T01:16:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h1><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><ul><li><p>FM优势：</p><ol><li><p>即使对于稀疏性大的问题中，也能有较好的效果；</p></li><li><p>线性复杂度</p></li><li>是一种通用的预测器，可以用于任何真实值的特征向量</li></ol></li><li><p>其他相关方法：SVM，MF等</p></li><li>最常见预测任务是估计一个函数$y:\mathbb{R}^n \to T$, 从一个真实的值 $x$ 到目标域T( 回归任务中T=R，分类任务中是T = {0,1} or {+，-} )</li><li>在本问题中$x$ 被设定成很稀疏的向量，即大多数$x_i$都是0；令$m(x)$ 表示$x$中的非零元素的个数；令$\overline{m}_D$ 表示$m(x)$ 的平均值。巨大的稀疏性使得：$\overline{m}_D &lt;&lt; n$, $n$是$x$的维度</li></ul><hr><ul><li><p>举个例子:</p><p>|      | A    | B    | C    | TI   | NH   | SW   | ST   | TI   | NH   | SW   | ST   | time | TI   | NH   | SW   | ST   | target |      |<br>| —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | ——— | —— |<br>| x1   | 1    | 0    | 0    | 1    | 0    | 0    | 0    | 0.3  | 0.3  | 0.3  | 0    | 13   | 0    | 0    | 0    | 0    | 5      | y1   |<br>| x2   | 1    | 0    | 0    | 0    | 1    | 0    | 0    | 0.3  | 0.3  | 0.3  | 0    | 14   | 1    | 0    | 0    | 0    | 3      | y2   |<br>| x3   | 1    | 0    | 0    | 0    | 0    | 1    | 0    | 0.3  | 0.3  | 0.3  | 0    | 16   | 0    | 1    | 0    | 0    | 1      | y3   |<br>| x4   | 0    | 1    | 0    | 0    | 0    | 1    | 0    | 0    | 0    | 0.5  | 0.5  | 5    | 0    | 0    | 0    | 0    | 4      | y4   |<br>| x5   | 0    | 1    | 0    | 0    | 0    | 0    | 1    | 0    | 0    | 0.5  | 0.5  | 8    | 0    | 0    | 1    | 0    | 5      | y5   |<br>| x6   | 0    | 0    | 1    | 1    | 0    | 0    | 0    | 0.5  | 0    | 0.5  | 0    | 9    | 0    | 0    | 0    | 0    | 1      | y6   |<br>| x7   | 0    | 0    | 1    | 0    | 0    | 1    | 0    | 0.5  | 0    | 0.5  | 0    | 12   | 1    | 0    | 0    | 0    | 5      | y7   |</p><p>U = {Alice(A), Bob(B), Charlie(C)}</p><p>I = {Titanic (TI), Notting Hill (NH), Star Wars (SW), Star Trek (ST)}</p><p>S = {(A, TI, 2010-1, 5),  (A,NH, 2010-2, 3),  (A, SW, 2010-4, 1),  (B, SW, 2009-5, 4),  </p><p>​        (B, ST, 2009-8, 5), (C, TI, 2009-9, 1),  (C, SW, 2009-12, 5)}</p><ul><li><p>前面的A、B、C 表示第i条S中的记录是否包含user</p></li><li><p>第一个TI，表示第i条S中的记录是否包含该movie</p></li><li><p>第二个TI，对每个用户进行标准化，比如说A看过TI、NH、SW，那么这三个就分别是0.3</p></li><li><p>time表示S记录中时间，2009年1月为1，后面的每个月递增</p></li><li><p>第三个TI表示，看该movie之前，user看了那部电影</p></li><li><p>target表示评分</p><p><strong>横着的一行表示一个向量$x$</strong></p></li></ul><hr><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><strong>model equation</strong></p><script type="math/tex; mode=display">\hat{y}(x) = w_0+\sum_{i=1}^{n}w_ix_i +\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}<v_i,v_j>x_ix_j</script><p>前半部分是常见的线性表达式，$w_0$为初始偏置常数，$w_i$为每一个$x_i$的权重(系数)，前半部分描述了每个特征和输出的关系。</p><p>FM比线性表达式多出了一个交叉项</p><script type="math/tex; mode=display"><v_i,v_j> = \sum_{f=1}^{k} v_{i,f}v_{j,f}\\v_i \in \mathbb{R}^{n \times k}</script><p>$v_i$ 是用k个因子表示第$i$个变量；我理解的$<v_i,v_j>$表示第i个和第j个向量的交互作用</v_i,v_j></p><p><strong>求解交互项</strong></p><ul><li><p>正定矩阵W可以写成：$W = V\cdot V^T$</p></li><li><p>proof</p><p><img src="/2019/12/04/FM-factorization-machine/FM.png" alt="FM"></p><p>可以看出这个等式的复杂度是$O(kn)$ , 另外在稀疏性条件下，$x$的大多数元素是0，因此复杂度可以降到$O(k\overline{m}_D)$</p></li></ul><hr><h3 id="用作预测器"><a href="#用作预测器" class="headerlink" title="用作预测器"></a>用作预测器</h3><p>FM可以在很多预测任务中：</p><ol><li>Regression : $\hat{y}(x)$ 可以直接用来预测，优化的标准是$D(y,\hat{y})$ 最小</li><li>Binary Classification : </li><li>Ranking : x 通过 $\hat{y}(x)$ 进行排序</li></ol><p><strong>learn FM</strong></p><p><img src="/2019/12/04/FM-factorization-machine/FM1.png" alt="learn"></p><p>第三项与 i 无关，因此可以提前计算。</p><p>使用<strong>SGD</strong>可以训练得到结果。</p></li></ul><hr><h3 id="与SVM进行比较"><a href="#与SVM进行比较" class="headerlink" title="与SVM进行比较"></a>与SVM进行比较</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FM&quot;&gt;&lt;a href=&quot;#FM&quot; class=&quot;headerlink&quot; title=&quot;FM&quot;&gt;&lt;/a&gt;FM&lt;/h1&gt;&lt;h3 id=&quot;背景知识&quot;&gt;&lt;a href=&quot;#背景知识&quot; class=&quot;headerlink&quot; title=&quot;背景知识&quot;&gt;&lt;/a&gt;背景知识&lt;/h
      
    
    </summary>
    
    
      <category term="recommender system" scheme="https://hhh0hwz.github.io/categories/recommender-system/"/>
    
    
  </entry>
  
  <entry>
    <title>EM算法</title>
    <link href="https://hhh0hwz.github.io/2019/12/04/EM%E7%AE%97%E6%B3%95/"/>
    <id>https://hhh0hwz.github.io/2019/12/04/EM%E7%AE%97%E6%B3%95/</id>
    <published>2019-12-04T02:57:00.000Z</published>
    <updated>2019-12-04T02:57:02.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>github page</title>
    <link href="https://hhh0hwz.github.io/2019/12/04/github-page/"/>
    <id>https://hhh0hwz.github.io/2019/12/04/github-page/</id>
    <published>2019-12-04T01:40:18.000Z</published>
    <updated>2019-12-04T02:52:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="github-page-hexo"><a href="#github-page-hexo" class="headerlink" title="github page + hexo"></a>github page + hexo</h1><p>前段时间，用Jekyll搭建了一个静态博客，但是jekyll对于公式的支持不是很好，而且其编辑工具jekyll writer好久没有更新了，我已经开始怀疑这个jekyll是否还有人在用了。</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="node-js"><a href="#node-js" class="headerlink" title="node.js"></a>node.js</h3><p>去官网下载就可以了：<a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a></p><p>安装直接一路next</p><h3 id="github注册"><a href="#github注册" class="headerlink" title="github注册"></a>github注册</h3><p>注册一个github的帐号</p><h3 id="git"><a href="#git" class="headerlink" title="git"></a>git</h3><h5 id="git的一些命令"><a href="#git的一些命令" class="headerlink" title="git的一些命令"></a>git的一些命令</h5><p>git我会的也不是很多，还需要学习，过段时间，学习完git再写一篇</p><p>具体的参加廖雪峰的教程：<a href="https://www.liaoxuefeng.com/wiki/896043488029600" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/896043488029600</a></p><ul><li><p><code>git init</code> 将一个空文件夹，初始化为一个git仓库，在文件夹中会有一个隐藏文件夹<code>.git</code></p></li><li><p><code>git add xxxx</code> 将文件<code>xxxx</code> 添加到仓库中。也可以使用<code>git add all</code> 将全部的文件都添加</p></li><li><p><code>git commit -m &quot;描述&quot;</code> 将刚才<code>add</code> 的文件提交到git中</p><p>添加文件分两步：<code>add</code> 和<code>commit</code></p></li></ul><p>和github相关的git操作</p><ul><li><code>ssh-keygen -t rsa -C &quot;youremail@example.com&quot;</code> 创建密钥，如果想要本地的git和github连接这是必要的；命令执行后，你可以在用户主目录看到<code>.ssh</code>文件夹，里面有<code>id_rsa</code>和<code>id_rsa.pub</code>两个文件，前者是私钥，后者是公钥。</li><li>登陆github，打开“Account setting”，“SSH keys”界面，新建keys，将<code>id_rsa.pub</code>里的内容copy进去</li><li><code>git remote add origin git@github.com:hhh0hwz/xxx.git</code>将github上的<code>xxx.git</code> 和本地的仓库连接</li><li><code>git push -u origin master</code> 首次使用加<code>-u</code> ，以后就可以不加了</li><li><code>git clone git@github.com:hhh0hwz/xxx.git</code> 将<code>xxx.git</code> 克隆到本地，注意后面的git部分，也可以使用http协议</li></ul><h5 id="git的安装"><a href="#git的安装" class="headerlink" title="git的安装"></a>git的安装</h5><p>git安装也是一路next</p><p>不过安装结束之后，需要在git bash中输入两条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;Your name&quot;</span><br><span class="line">$ git config --global user.email &quot;email@example.com&quot;</span><br></pre></td></tr></table></figure><h2 id="正式工作"><a href="#正式工作" class="headerlink" title="正式工作"></a>正式工作</h2><ol><li><p>新建一个空文件夹 <code>.\hexo</code></p></li><li><p>打开命令行，进入到该文件夹中；在命令行中输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; npm install hexo-cli -g</span><br><span class="line">&gt; npm install hexo --save</span><br></pre></td></tr></table></figure></li><li><p>新建一个blog文件夹，并在命令行中进入到该目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; hexo init</span><br><span class="line">&gt; npm install</span><br></pre></td></tr></table></figure></li><li><p>接下来的操作可以看另一篇post “<strong>hexo-总结</strong>”</p></li><li><p>将hexo和GitHub联系起来</p><ol><li><p>配置git，即设置git的用户名和邮箱，生成rsa密钥</p></li><li><p>配置hexo</p><ol><li><p>打开<code>.\blog</code> 目录下的<code>_config.yml</code>文件，进行如下修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line"> type: git</span><br><span class="line"> repo: git@github.com:yourname&#x2F;youname.github.io.git</span><br><span class="line"> branch: master</span><br></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>经过上一步之后，就可以开始写博客了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new post &quot;article title&quot;</span><br></pre></td></tr></table></figure><p>使用maekdown编辑器(推荐Typora)编辑好之后,运行生成，部署命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d &#x2F;&#x2F;部署到github上，如果想在本地预览，可以用 hexo s 命令</span><br></pre></td></tr></table></figure></li><li><p>主题的配置，推荐next主题，可以看按照官网给出的选项来。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;github-page-hexo&quot;&gt;&lt;a href=&quot;#github-page-hexo&quot; class=&quot;headerlink&quot; title=&quot;github page + hexo&quot;&gt;&lt;/a&gt;github page + hexo&lt;/h1&gt;&lt;p&gt;前段时间，用Jeky
      
    
    </summary>
    
    
      <category term="hexo" scheme="https://hhh0hwz.github.io/categories/hexo/"/>
    
    
      <category term="hexo" scheme="https://hhh0hwz.github.io/tags/hexo/"/>
    
      <category term="github" scheme="https://hhh0hwz.github.io/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>hexo-总结</title>
    <link href="https://hhh0hwz.github.io/2019/12/03/hexo-%E6%80%BB%E7%BB%93/"/>
    <id>https://hhh0hwz.github.io/2019/12/03/hexo-%E6%80%BB%E7%BB%93/</id>
    <published>2019-12-03T12:32:24.000Z</published>
    <updated>2019-12-03T13:39:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="hexo总结"><a href="#hexo总结" class="headerlink" title="hexo总结"></a>hexo总结</h1><h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><ul><li><code>hexo g</code>                   生成html文件</li><li><code>hexo clean</code>           清除html文件、缓存</li><li><code>hexo s</code>                   打开server，可以在本地预览 <code>http://localhost:4000/</code></li><li><code>hexo d</code>                   将修改上传到github上，配和<code>hexo g</code> 使用</li><li><code>hexo n xxxx</code>         新建一个post，<code>xxxx</code>是post的名字</li></ul><h2 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h2><p><a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">参考这篇文章可以解决大多数数学公式的问题</a></p><p>如果使用Typora，那么，文件-&gt;偏好设置-&gt; markdown -&gt;内联公式(打勾),即可用 $$ 表示行内公式。</p><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><ol><li>需要安装一个插件</li></ol><p><code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code></p><ol><li><p>后续步骤参照</p><p><a href="https://blog.csdn.net/xjm850552586/article/details/84101345" target="_blank" rel="noopener">https://blog.csdn.net/xjm850552586/article/details/84101345</a></p></li></ol><p>实测可行</p><h2 id="Typora"><a href="#Typora" class="headerlink" title="Typora"></a>Typora</h2><ul><li><p>typora是一款十分好用的markdown编辑器，进行完上述的操作后，会支持插入图片和数学公式。</p></li><li><p>相关语法：</p><ul><li><p># 一级标题  Ps.#和title之间有一个空格</p></li><li><p>## 二级标题</p></li><li><p>更详细的参见markdown语法：</p><p><a href="https://www.jianshu.com/p/092de536d948" target="_blank" rel="noopener">https://www.jianshu.com/p/092de536d948</a></p></li></ul></li></ul><p>如果后续有问题，会继续更新，暂时没有碰到更多的问题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;hexo总结&quot;&gt;&lt;a href=&quot;#hexo总结&quot; class=&quot;headerlink&quot; title=&quot;hexo总结&quot;&gt;&lt;/a&gt;hexo总结&lt;/h1&gt;&lt;h2 id=&quot;命令&quot;&gt;&lt;a href=&quot;#命令&quot; class=&quot;headerlink&quot; title=&quot;命令&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="hexo" scheme="https://hhh0hwz.github.io/categories/hexo/"/>
    
    
      <category term="hexo" scheme="https://hhh0hwz.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>TransE</title>
    <link href="https://hhh0hwz.github.io/2019/12/03/TransE-paper/"/>
    <id>https://hhh0hwz.github.io/2019/12/03/TransE-paper/</id>
    <published>2019-12-03T10:55:59.000Z</published>
    <updated>2019-12-06T01:47:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li>对multi-relation data的实体和关系建立embedding；</li><li>目标是提出一个模型：参数少容易训练，可以扩展到大规模数据上。</li></ul><h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><ul><li><p>TransE将三元组(head,relation,tail)，基于向量表示，不断调整h,l,t(head,realtion,tail的向量表示)，使得h+l尽可能与t相等。</p></li><li><p>为此，作者定义了两者之间的距离表示(欧式距离)： </p><script type="math/tex; mode=display">d(h+l,t) = \Arrowvert h+l-t\Arrowvert^2=\Arrowvert h \Arrowvert^2 + \Arrowvert l \Arrowvert^2 + \Arrowvert t \Arrowvert^2 -2(h^Tt+l^T(t-h))</script></li><li><p>TransE的算法流程如下：</p><p><img src="/2019/12/03/TransE-paper/transe.png" alt="transe"></p></li></ul><p>其中，</p><script type="math/tex; mode=display">\mathcal{L} = \sum\limits_{(h,l,t)\in S,(h',l,t')\in S'}[\gamma+d(h+l,t)-d(h'+l,t')]_{+}</script><p>$[x]_+$ 表示x的positive part，$\gamma$ 表示margin hyperparameter，并且</p><script type="math/tex; mode=display">S'_{(h',l,t')} = [(h',l,t)|h' \in E ] \cup[(h,l,t')|t' \in E]</script><p>我们使前者尽可能小(原有的三元组)，后者尽可能大。</p><p>参数的更新，我们使用<strong>随机梯度下降</strong>(Stochastic Gradient Descent，SGD).</p><ul><li>论文后面的部分是实验部分</li></ul><h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><h3 id="1-data"><a href="#1-data" class="headerlink" title="1. data"></a>1. data</h3><p>Ps. 最后彻底丢弃记事本，它的数据格式和大多数数据都不符合。推荐使用notepad++</p><ul><li>entity2id.txt: all entities and corresponding ids, one per line.</li><li>relation2id.txt: all relations and corresponding ids, one per line.</li><li>train.txt: training file, format (e1, e2, rel).</li></ul><h3 id="2-code"><a href="#2-code" class="headerlink" title="2.code"></a>2.code</h3><p>见github</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransE&quot;&gt;&lt;a href=&quot;#TransE&quot; class=&quot;headerlink&quot; title=&quot;TransE&quot;&gt;&lt;/a&gt;TransE&lt;/h1&gt;&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
      <category term="Knowledge Graph" scheme="https://hhh0hwz.github.io/categories/Knowledge-Graph/"/>
    
    
      <category term="embedding" scheme="https://hhh0hwz.github.io/tags/embedding/"/>
    
  </entry>
  
</feed>
